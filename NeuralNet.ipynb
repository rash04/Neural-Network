{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NETWORK MODEL\n",
    "\n",
    "import random\n",
    "from random import randint\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "import csv\n",
    "\n",
    "# Helper functions\n",
    "def sig(x):\n",
    "    return 1.0/(1.0+np.exp(-x))\n",
    "\n",
    "def sigderivative(x):\n",
    "    return sig(x)*(1-sig(x))\n",
    "\n",
    "class NeuralNet(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.neurons = [4096, 100, 10]\n",
    "        self.layers = len(self.neurons)\n",
    "        self.w = [np.random.randn(y, x) for x, y in zip(self.neurons[:-1], self.neurons[1:])]\n",
    "        self.b = [np.random.randn(y, 1) for y in self.neurons[1:]]\n",
    "        self.err = 0\n",
    "\n",
    "    def train(self, data, epochs, batchsize, lr):\n",
    "        print('starting...')\n",
    "        for j in range(epochs):\n",
    "            print('epoch:' + str(j))\n",
    "            random.shuffle(data)\n",
    "            batches = [data[z:z+batchsize] for z in range(0, len(data), batchsize)]\n",
    "            for i, batch in enumerate(batches):\n",
    "                if i % 500 == 0:\n",
    "                    print('epoch:' + str(j) + ' ... ' + str(100*i/len(batches)) + '% ... err:' + str(self.err/500))\n",
    "                    self.err = 0\n",
    "                self.calcgradient(batch, lr)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for b, w in zip(self.b, self.w):\n",
    "            x = sig(np.dot(w, x)+b)\n",
    "        return x\n",
    "\n",
    "    def calcgradient(self, batch, lr):\n",
    "        b = [np.zeros(b.shape) for b in self.b]\n",
    "        w = [np.zeros(w.shape) for w in self.w]\n",
    "        for x, y in batch:\n",
    "            db, dw = self.back(x, y)\n",
    "            b = [bval+dbval for bval, dbval in zip(b, db)]\n",
    "            w = [wval+dwval for wval, dwval in zip(w, dw)]\n",
    "        self.w = [wval-(lr/len(batch))*nwval for wval, nwval in zip(self.w, w)]\n",
    "        self.b = [bval-(lr/len(batch))*nbval for bval, nbval in zip(self.b, b)]\n",
    "\n",
    "    def back(self, x, y):\n",
    "        nb = [np.zeros(b.shape) for b in self.b]\n",
    "        nw = [np.zeros(w.shape) for w in self.w]\n",
    "        net = x\n",
    "        nets = [x]\n",
    "        outputs = []\n",
    "        for b, w in zip(self.b, self.w):\n",
    "            o = np.dot(w, net)+b\n",
    "            outputs.append(o)\n",
    "            net = sig(o)\n",
    "            nets.append(net)\n",
    "        delta = self.errderivative(nets[-1], y) * sigderivative(outputs[-1])\n",
    "        nb[-1] = delta\n",
    "        nw[-1] = np.dot(delta, nets[-2].transpose())\n",
    "        for layer in range(2, self.layers):\n",
    "            o = outputs[-layer]\n",
    "            do = sigderivative(o)\n",
    "            delta = np.dot(self.w[-layer+1].transpose(), delta) * do\n",
    "            nb[-layer] = delta\n",
    "            nw[-layer] = np.dot(delta, nets[-layer-1].transpose())\n",
    "        return (nb, nw)\n",
    "\n",
    "    def predict(self, data):\n",
    "        predictions = [(self.forward(x), y) for (x, y) in data]\n",
    "        return sum(int(p == y) for (p, y) in predictions)\n",
    "\n",
    "    def errderivative(self, o, y):\n",
    "        errvec = (o-y)\n",
    "        err = 0\n",
    "        for e in errvec:\n",
    "            err += (e**2)/2\n",
    "        self.err += err\n",
    "        return errvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATA\n",
    "traindata = np.load('train_x_sparse.npz')\n",
    "traindata = csr_matrix((traindata['data'], traindata['indices'], traindata['indptr']), shape=traindata['shape'])\n",
    "\n",
    "with open('train_y.csv') as f:\n",
    "    trainy = f.readlines()\n",
    "totaly = []\n",
    "for i, s in enumerate(trainy):\n",
    "    index = int(trainy[i].replace('\\n', ''))\n",
    "    tempy = np.zeros(10)\n",
    "    tempy[index] = 1.0\n",
    "    totaly.append(tempy)\n",
    "trainy = totaly\n",
    "        \n",
    "datax = []\n",
    "datay = []\n",
    "for x in range(0, traindata.shape[0]-1):\n",
    "    tup = []\n",
    "    datax.append(np.reshape(traindata.getrow(x).toarray(), (4096, 1)))\n",
    "    datay.append(np.reshape(trainy[x], (10, 1)))\n",
    "data = list(zip(datax, datay))\n",
    "random.shuffle(data)\n",
    "testdata = data[:10000]\n",
    "data = data[10000:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting...\n",
      "epoch:0\n",
      "epoch:0 ... 0.0% ... err:0.0\n",
      "epoch:0 ... 10.0% ... err:[5.32503363]\n",
      "epoch:0 ... 20.0% ... err:[5.00535392]\n",
      "epoch:0 ... 30.0% ... err:[5.00819138]\n",
      "epoch:0 ... 40.0% ... err:[5.00398292]\n",
      "epoch:0 ... 50.0% ... err:[4.99941735]\n",
      "epoch:0 ... 60.0% ... err:[5.00224466]\n",
      "epoch:0 ... 70.0% ... err:[4.99834222]\n",
      "epoch:0 ... 80.0% ... err:[4.99850272]\n",
      "epoch:0 ... 90.0% ... err:[5.00213036]\n",
      "epoch:1\n",
      "epoch:1 ... 0.0% ... err:[4.99770489]\n",
      "epoch:1 ... 10.0% ... err:[4.9964541]\n",
      "epoch:1 ... 20.0% ... err:[4.99565416]\n",
      "epoch:1 ... 30.0% ... err:[4.99761091]\n",
      "epoch:1 ... 40.0% ... err:[4.99564777]\n",
      "epoch:1 ... 50.0% ... err:[4.99752272]\n",
      "epoch:1 ... 60.0% ... err:[4.99550436]\n",
      "epoch:1 ... 70.0% ... err:[4.99722789]\n",
      "epoch:1 ... 80.0% ... err:[4.99190906]\n",
      "epoch:1 ... 90.0% ... err:[4.99142041]\n",
      "epoch:2\n",
      "epoch:2 ... 0.0% ... err:[4.99395988]\n",
      "epoch:2 ... 10.0% ... err:[4.99058891]\n",
      "epoch:2 ... 20.0% ... err:[4.98488039]\n",
      "epoch:2 ... 30.0% ... err:[4.98649685]\n",
      "epoch:2 ... 40.0% ... err:[4.99165757]\n",
      "epoch:2 ... 50.0% ... err:[4.99493247]\n",
      "epoch:2 ... 60.0% ... err:[4.98998474]\n",
      "epoch:2 ... 70.0% ... err:[4.98874]\n",
      "epoch:2 ... 80.0% ... err:[4.98725431]\n",
      "epoch:2 ... 90.0% ... err:[4.99150977]\n",
      "epoch:3\n",
      "epoch:3 ... 0.0% ... err:[4.9885885]\n",
      "epoch:3 ... 10.0% ... err:[4.98682516]\n",
      "epoch:3 ... 20.0% ... err:[4.97502236]\n",
      "epoch:3 ... 30.0% ... err:[4.98467068]\n",
      "epoch:3 ... 40.0% ... err:[4.98261513]\n",
      "epoch:3 ... 50.0% ... err:[4.98125912]\n",
      "epoch:3 ... 60.0% ... err:[4.9921992]\n",
      "epoch:3 ... 70.0% ... err:[4.98141094]\n",
      "epoch:3 ... 80.0% ... err:[4.98716057]\n",
      "epoch:3 ... 90.0% ... err:[4.97386694]\n",
      "epoch:4\n",
      "epoch:4 ... 0.0% ... err:[4.97648414]\n",
      "epoch:4 ... 10.0% ... err:[4.97406993]\n",
      "epoch:4 ... 20.0% ... err:[4.97320525]\n",
      "epoch:4 ... 30.0% ... err:[4.97128899]\n",
      "epoch:4 ... 40.0% ... err:[4.97997749]\n",
      "epoch:4 ... 50.0% ... err:[4.96723632]\n",
      "epoch:4 ... 60.0% ... err:[4.97337966]\n",
      "epoch:4 ... 70.0% ... err:[4.97304194]\n",
      "epoch:4 ... 80.0% ... err:[4.97114947]\n",
      "epoch:4 ... 90.0% ... err:[4.96512303]\n",
      "epoch:5\n",
      "epoch:5 ... 0.0% ... err:[4.97624896]\n",
      "epoch:5 ... 10.0% ... err:[4.96659328]\n",
      "epoch:5 ... 20.0% ... err:[4.96255964]\n",
      "epoch:5 ... 30.0% ... err:[4.95968459]\n",
      "epoch:5 ... 40.0% ... err:[4.95630356]\n",
      "epoch:5 ... 50.0% ... err:[4.95391622]\n",
      "epoch:5 ... 60.0% ... err:[4.96119947]\n",
      "epoch:5 ... 70.0% ... err:[4.96063997]\n",
      "epoch:5 ... 80.0% ... err:[4.95086009]\n",
      "epoch:5 ... 90.0% ... err:[4.95819436]\n",
      "epoch:6\n",
      "epoch:6 ... 0.0% ... err:[4.96322093]\n",
      "epoch:6 ... 10.0% ... err:[4.94033306]\n",
      "epoch:6 ... 20.0% ... err:[4.93871151]\n",
      "epoch:6 ... 30.0% ... err:[4.94406927]\n",
      "epoch:6 ... 40.0% ... err:[4.94177854]\n",
      "epoch:6 ... 50.0% ... err:[4.9545646]\n",
      "epoch:6 ... 60.0% ... err:[4.94044916]\n",
      "epoch:6 ... 70.0% ... err:[4.94058087]\n",
      "epoch:6 ... 80.0% ... err:[4.92782325]\n",
      "epoch:6 ... 90.0% ... err:[4.94267662]\n",
      "epoch:7\n",
      "epoch:7 ... 0.0% ... err:[4.9370127]\n",
      "epoch:7 ... 10.0% ... err:[4.92426965]\n",
      "epoch:7 ... 20.0% ... err:[4.92085316]\n",
      "epoch:7 ... 30.0% ... err:[4.92318402]\n",
      "epoch:7 ... 40.0% ... err:[4.91096584]\n",
      "epoch:7 ... 50.0% ... err:[4.89554416]\n",
      "epoch:7 ... 60.0% ... err:[4.90444391]\n",
      "epoch:7 ... 70.0% ... err:[4.91695052]\n",
      "epoch:7 ... 80.0% ... err:[4.90933611]\n",
      "epoch:7 ... 90.0% ... err:[4.91515236]\n",
      "epoch:8\n",
      "epoch:8 ... 0.0% ... err:[4.91466179]\n",
      "epoch:8 ... 10.0% ... err:[4.87385827]\n",
      "epoch:8 ... 20.0% ... err:[4.90008914]\n",
      "epoch:8 ... 30.0% ... err:[4.87920376]\n",
      "epoch:8 ... 40.0% ... err:[4.89034995]\n",
      "epoch:8 ... 50.0% ... err:[4.89139575]\n",
      "epoch:8 ... 60.0% ... err:[4.89070235]\n",
      "epoch:8 ... 70.0% ... err:[4.89219248]\n",
      "epoch:8 ... 80.0% ... err:[4.88868958]\n",
      "epoch:8 ... 90.0% ... err:[4.89338022]\n",
      "epoch:9\n",
      "epoch:9 ... 0.0% ... err:[4.9077956]\n",
      "epoch:9 ... 10.0% ... err:[4.87000794]\n",
      "epoch:9 ... 20.0% ... err:[4.8915285]\n",
      "epoch:9 ... 30.0% ... err:[4.87323373]\n",
      "epoch:9 ... 40.0% ... err:[4.86438414]\n",
      "epoch:9 ... 50.0% ... err:[4.87824351]\n",
      "epoch:9 ... 60.0% ... err:[4.88195889]\n",
      "epoch:9 ... 70.0% ... err:[4.87734945]\n",
      "epoch:9 ... 80.0% ... err:[4.87850603]\n",
      "epoch:9 ... 90.0% ... err:[4.8766441]\n"
     ]
    }
   ],
   "source": [
    "#TRAINING\n",
    "net = NeuralNet()\n",
    "net.train(data, 10, 10, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('wNN6-100-10', net.w)\n",
    "np.save('bNN6-100-10', net.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1208\n"
     ]
    }
   ],
   "source": [
    "#LOAD SAVED MODEL AND TEST\n",
    "\n",
    "def forward(x, w, b):\n",
    "    for tb, tw in zip(b, w):\n",
    "        x = sig(np.dot(tw, x)+tb)\n",
    "    return x\n",
    "\n",
    "def predict(data, w, b):\n",
    "    pr = [(forward(x, w, b), y) for (x, y) in data]\n",
    "    predictions = [(np.argmax(forward(x, w, b)), np.argmax(y)) for (x, y) in data]\n",
    "    return sum(int(p == y) for (p, y) in predictions)\n",
    "\n",
    "w = np.load('wNN6-100-10.npy')\n",
    "b = np.load('bNN6-100-10.npy')\n",
    "\n",
    "with open('train_y.csv') as f:\n",
    "    trainy = f.readlines()\n",
    "\n",
    "print(predict(testdata, w, b)/10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
